{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPDsQZBIOTI/By//vg6hESI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/m-wessler/nbm-verification/blob/main/get_nbm_aws_streamline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "mCU01BOdhCx5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install boto3\n",
        "!pip install pygrib\n",
        "\n",
        "import os, pathlib\n",
        "import boto3, pygrib\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from botocore import UNSIGNED\n",
        "from botocore.client import Config\n",
        "from multiprocessing import Pool, cpu_count"
      ],
      "metadata": {
        "id": "ZP6Vq6urQJst"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Globals"
      ],
      "metadata": {
        "id": "RgfkSfCGhEe2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Globals\n",
        "aws_bucket = 'noaa-nbm-grib2-pds'\n",
        "\n",
        "# Where to place the grib file (subdirs can be added in local) (not used)\n",
        "# output_dir = './'\n",
        "\n",
        "# Which grib variables do each element correlate with\n",
        "element_var = {'qpf':['APCP'],\n",
        "                  'maxt':['TMP', 'TMAX', 'APTMP'],\n",
        "                  'mint':['TMP', 'TMIN', 'APTMP']}\n",
        "\n",
        "# Which grib levels do each element correlate with\n",
        "element_lev = {'qpf':'surface',\n",
        "               'maxt':'2 m above ground',\n",
        "               'mint':'2 m above ground'}\n",
        "\n",
        "# If a grib message contains any of these, exclude\n",
        "excludes = ['ens std dev', '% lev']"
      ],
      "metadata": {
        "id": "mlF-5hehQNbZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Methods"
      ],
      "metadata": {
        "id": "T7TMDADMhK5f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mkdir_p(path):\n",
        "    pathlib.Path(path).mkdir(parents=True, exist_ok=True)\n",
        "    return path"
      ],
      "metadata": {
        "id": "Gh_idcAe3bly"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cwa_list(input_region):\n",
        "\n",
        "    input_region = input_region.upper()\n",
        "\n",
        "    region_dict ={\n",
        "        \"WR\":[\"BYZ\", \"BOI\", \"LKN\", \"EKA\", \"FGZ\", \"GGW\", \"TFX\", \"VEF\", \"LOX\", \"MFR\",\n",
        "            \"MSO\", \"PDT\", \"PSR\", \"PIH\", \"PQR\", \"REV\", \"STO\", \"SLC\", \"SGX\", \"MTR\",\n",
        "            \"HNX\", \"SEW\", \"OTX\", \"TWC\"],\n",
        "\n",
        "        \"CR\":[\"ABR\", \"BIS\", \"CYS\", \"LOT\", \"DVN\", \"BOU\", \"DMX\", \"DTX\", \"DDC\", \"DLH\",\n",
        "            \"FGF\", \"GLD\", \"GJT\", \"GRR\", \"GRB\", \"GID\", \"IND\", \"JKL\", \"EAX\", \"ARX\",\n",
        "            \"ILX\", \"LMK\", \"MQT\", \"MKX\", \"MPX\", \"LBF\", \"APX\", \"IWX\", \"OAX\", \"PAH\",\n",
        "            \"PUB\", \"UNR\", \"RIW\", \"FSD\", \"SGF\", \"LSX\", \"TOP\", \"ICT\"],\n",
        "\n",
        "        \"ER\":[\"ALY\", \"LWX\", \"BGM\", \"BOX\", \"BUF\", \"BTV\", \"CAR\", \"CTP\", \"RLX\", \"CHS\",\n",
        "            \"ILN\", \"CLE\", \"CAE\", \"GSP\", \"MHX\", \"OKX\", \"PHI\", \"PBZ\", \"GYX\", \"RAH\",\n",
        "            \"RNK\", \"AKQ\", \"ILM\"],\n",
        "\n",
        "        \"SR\":[\"ABQ\", \"AMA\", \"FFC\", \"EWX\", \"BMX\", \"BRO\", \"CRP\", \"EPZ\", \"FWD\", \"HGX\",\n",
        "            \"HUN\", \"JAN\", \"JAX\", \"KEY\", \"MRX\", \"LCH\", \"LZK\", \"LUB\", \"MLB\", \"MEG\",\n",
        "            \"MAF\", \"MFL\", \"MOB\", \"MRX\", \"OHX\", \"LIX\", \"OUN\", \"SJT\", \"SHV\", \"TAE\",\n",
        "            \"TBW\", \"TSA\"]}\n",
        "\n",
        "    if input_region == \"CONUS\":\n",
        "        return np.hstack([region_dict[region] for region in region_dict.keys()])\n",
        "    else:\n",
        "        return region_dict[input_region]"
      ],
      "metadata": {
        "id": "I5dQfL_xiNHO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ro8LqKJLQB4r"
      },
      "outputs": [],
      "source": [
        "def fetch_grib_from_AWS(**req):\n",
        "\n",
        "    output_dir = mkdir_p('./nbm/')\n",
        "    output_file = output_dir + f'{req[\"yyyymmdd\"]}.t{req[\"hh\"]:02d}z.' +\\\n",
        "                    f'fhr{req[\"fhr\"]:03d}.{element}.grib2'\n",
        "\n",
        "    if os.path.isfile(output_file):\n",
        "        return output_file\n",
        "\n",
        "    else:\n",
        "        for nbm_set in req['nbm_set']:\n",
        "\n",
        "            bucket_dir = f'blend.{req[\"yyyymmdd\"]}/{req[\"hh\"]:02d}/{nbm_set}/'\n",
        "\n",
        "            grib_file = f'{bucket_dir}blend.t{req[\"hh\"]:02d}z.'+\\\n",
        "                        f'{nbm_set}.f{req[\"fhr\"]:03d}.{req[\"nbm_area\"]}.grib2'\n",
        "\n",
        "            index_file = f'{grib_file}.idx'\n",
        "\n",
        "            print(index_file)\n",
        "\n",
        "            client = boto3.client('s3', config=Config(signature_version=UNSIGNED))\n",
        "\n",
        "            index_data_raw = client.get_object(\n",
        "                Bucket=aws_bucket, Key=index_file)['Body'].read().decode().split('\\n')\n",
        "\n",
        "            cols = ['num', 'byte', 'date', 'var', 'level',\n",
        "                'forecast', 'fthresh', 'ftype', '']\n",
        "\n",
        "            # index_data = pd.DataFrame([item.split(':') for item in index_data_raw],\n",
        "            #                 columns=cols if nbm_set == 'core' else cols[:-1])\n",
        "\n",
        "            index_data_parsed = [item.split(':') for item in index_data_raw]\n",
        "\n",
        "            try:\n",
        "                index_data = pd.DataFrame(index_data_parsed, columns=cols)\n",
        "            except:\n",
        "                index_data = pd.DataFrame(index_data_parsed, columns=cols[:-1])\n",
        "\n",
        "            # Clean up any ghost indicies, set the index\n",
        "            index_data = index_data[index_data['num'] != '']\n",
        "            index_data['num'] = index_data['num'].astype(int)\n",
        "            index_data = index_data.set_index('num')\n",
        "\n",
        "            # Allow byte ranging to '' (EOF)\n",
        "            index_data.loc[index_data.shape[0]+1] = ['']*index_data.shape[1]\n",
        "\n",
        "            for req_var in req['var']:\n",
        "\n",
        "                print(req_var)\n",
        "\n",
        "                index_subset = index_data[\n",
        "                    ((index_data['var'] == req_var) &\n",
        "                    (index_data['level'] == req['level']))]\n",
        "\n",
        "                # byte start >> byte range\n",
        "                for i in index_subset.index:\n",
        "                    index_subset.loc[i]['byte'] = (\n",
        "                        index_data.loc[i, 'byte'],\n",
        "                        index_data.loc[int(i)+1, 'byte'])\n",
        "\n",
        "                # Filter out excluded vars\n",
        "                for ex in excludes:\n",
        "                    mask = np.column_stack([index_subset[col].str.contains(ex, na=False)\n",
        "                                            for col in index_subset])\n",
        "\n",
        "                    index_subset = index_subset.loc[~mask.any(axis=1)]\n",
        "\n",
        "                # Fetch the data by byte range, write from stream\n",
        "                for index, item in index_subset.iterrows():\n",
        "                    byte_range = f\"bytes={item['byte'][0]}-{item['byte'][1]}\"\n",
        "\n",
        "                    output_bytes = client.get_object(\n",
        "                        Bucket=aws_bucket, Key=grib_file, Range=byte_range)\n",
        "\n",
        "                    with open(output_file, 'ab') as wfp:\n",
        "                        for chunk in output_bytes['Body'].iter_chunks(chunk_size=4096):\n",
        "                            wfp.write(chunk)\n",
        "\n",
        "    client.close()\n",
        "    return output_file"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# User Input/Multiprocessing Inputs"
      ],
      "metadata": {
        "id": "AuVwvcXWhMPf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "element = 'qpf' # input('Desired element? (QPF/MaxT/MinT)').lower()"
      ],
      "metadata": {
        "id": "vtgrpivgQTNb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main/Multiprocessing Call"
      ],
      "metadata": {
        "id": "Irb9HzFAhTZm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build arg dict\n",
        "request_args = {\n",
        "    'yyyymmdd':'20231010', # input('Desired init date (YYYYMMDD)? '),\n",
        "    'hh':12, # int(input('Desired init hour int(HH)? ')),\n",
        "    'fhr':18, # int(input('Desired forecast hour/lead time int(HHH)?')),\n",
        "    'nbm_set':['core', 'qmd'] if element == 'qpf' else ['core'],\n",
        "    'nbm_area':'co',\n",
        "    'element':element,\n",
        "    'var':element_var[element],\n",
        "    'level':element_lev[element]}"
      ],
      "metadata": {
        "id": "igAjCkwNhYYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Do the job\n",
        "grib_output_file = fetch_grib_from_AWS(**request_args)"
      ],
      "metadata": {
        "id": "AqK9dCeUhkTX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the output\n",
        "for item in pygrib.open(grib_output_file).read():\n",
        "    print(item)"
      ],
      "metadata": {
        "id": "1-ReDYLChqO_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}